{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLu0DchDJ2pj",
        "outputId": "94af483b-c948-4369-bec4-b32aa813dde1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0TdGMKvJBjV",
        "outputId": "3352ad93-d527-4f74-dca2-f3bd5d00185e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "from transformers import BertTokenizer\n",
        "import nltk\n",
        "import re\n",
        "import pandas as pd\n",
        "nltk.download(\"punkt_tab\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the dataset"
      ],
      "metadata": {
        "id": "4KFOFFaaJP_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reddit_data = pd.read_csv(\"reddit_data.csv\")"
      ],
      "metadata": {
        "id": "1FwOhSRiJSE7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing function"
      ],
      "metadata": {
        "id": "W9uTGPBaJZOR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    text = re.sub(r\"http\\S+\", \"\", text)  # Remove links\n",
        "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)  # Remove special characters\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "    text = nltk.word_tokenize(text)  # Tokenize\n",
        "    return \" \".join(text)"
      ],
      "metadata": {
        "id": "Aj-JwO9gJaO3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Apply preprocessing"
      ],
      "metadata": {
        "id": "NEpKVSw5JcIf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reddit_data[\"cleaned_title\"] = reddit_data[\"title\"].apply(preprocess_text)\n",
        "reddit_data = reddit_data.dropna(subset=[\"cleaned_title\"])  # Drop rows with NaN\n",
        "reddit_data.to_csv(\"processed_reddit_data.csv\", index=False)\n",
        "print(\"Text preprocessing completed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DOGSMp7JeJa",
        "outputId": "b04400f2-931b-4b01-b914-e8e6cc24b5c8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text preprocessing completed.\n"
          ]
        }
      ]
    }
  ]
}